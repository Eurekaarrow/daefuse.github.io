<!DOCTYPE html>
<html>
<head>
  
  <meta charset="utf-8">
  <meta name="description"
        content="DAE-Fuse: An Adaptive Discriminative Autoencoder for Multi-Modality Image Fusion">
  <meta name="keywords" content="Image Fusion, Multi-Modality, Autoencoder, GAN, Computer Vision">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DAE-Fuse: An Adaptive Discriminative Autoencoder for Multi-Modality Image Fusion</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
<!--   <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://your-lab-website.com">
        <span class="icon"><i class="fas fa-home"></i></span>
      </a>
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">More Research</a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="#">Related Project 1</a>
          <a class="navbar-item" href="#">Related Project 2</a>
        </div>
      </div>
    </div>
  </div> -->
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
<!--           <h1 class="title is-1 publication-title">DAE-Fuse: An Adaptive Discriminative Autoencoder for Multi-Modality Image Fusion</h1> -->
          <h1 class="title is-2 publication-title" style="line-height: 1.2; letter-spacing: -0.5px;">
            DAE-Fuse<br class="is-hidden-touch"> 
            <span style="font-weight: 400;">
              An Adaptive Discriminative Autoencoder<br class="is-hidden-touch"> 
              for Multi-Modality Image Fusion
            </span>
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://eurekaarrow.github.io/">Yuchen Guo</a><sup></sup>,</span></span>
            <span class="author-block"><a href="https://www.linkedin.com/in/ruoxiang-xu-3934a2335/">Ruoxiang Xu</a><sup></sup>,</span></span>
            <span class="author-block"><a href="https://www.linkedin.com/in/rongcheng-li-8751152b6/">Rongcheng Li</a>,</span></span>
            <span class="author-block"><a href="https://staff.uic.edu.cn/wfsu/en">Weifeng Su</a><sup></sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"> Department of Computer Science </span>
            <span class="author-block"> Guangdong Provincial Key Laboratory of Interdisciplinary Research and Application for Data Science </span>
            <span class="author-block"> Beijing Normal - Hong Kong Baptist University </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://www.arxiv.org/pdf/2409.10080" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://www.arxiv.org/abs/2409.10080" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/ir_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fusion_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
  
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- 实验1 -->
      <div class="columns is-vcentered has-text-centered mb-6">
        <div class="column">
          <video controls class="video-frame" poster="./static/thumbnails/vis_1.jpg">
            <source src="./static/videos/vis_1.mp4" type="video/mp4">
            <source src="./static/videos/vis_1.webm" type="video/webm">
          </video>
          <p class="label mt-2">Visual 1</p>
        </div>
      </div>

      <!-- 实验2 -->
      <div class="columns is-vcentered has-text-centered mb-6">
        <div class="column">
          <video controls class="video-frame" src="./static/videos/vis_2.mp4"></video>
          <p class="label mt-2">Visual 2</p>
        </div>
        <div class="column">
          <video controls class="video-frame" src="./static/videos/ir_2.mp4"></video>
          <p class="label mt-2">Infrared 2</p>
        </div>
        <div class="column">
          <video controls class="video-frame" src="./static/videos/fusion_2.mp4"></video>
          <p class="label mt-2">Fusion 2</p>
        </div>
      </div>

      <!-- 实验3 -->
      <div class="columns is-vcentered has-text-centered">
        <div class="column">
          <video controls class="video-frame" src="./static/videos/vis_3.mp4"></video>
          <p class="label mt-2">Visual 3</p>
        </div>
        <div class="column">
          <video controls class="video-frame" src="./static/videos/ir_3.mp4"></video>
          <p class="label mt-2">Infrared 3</p>
        </div>
        <div class="column">
          <video controls class="video-frame" src="./static/videos/fusion_3.mp4"></video>
          <p class="label mt-2">Fusion 3</p>
        </div>
      </div>

      <h2 class="subtitle has-text-centered mt-5">
        DAE-Fuse integrates adversarial feature extraction and cross-modality attention<br>
        to achieve balanced multi-modality fusion.
      </h2>
    </div>
  </div>
</section>

<style>
.video-frame {
  width: 100%;
  max-width: 400px;
  height: auto;
  border-radius: 8px;
  box-shadow: 0 2px 15px rgba(0,0,0,0.1);
}

.label {
  font-size: 1.1rem;
  font-weight: 500;
  color: #333;
}
</style>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In extreme scenarios such as nighttime or low-visibility environments, achieving reliable perception is critical for applications like autonomous driving. We propose DAE-Fuse, a novel two-phase discriminative autoencoder framework that generates sharp and natural fused images by combining adversarial learning with cross-modality attention. Our method pioneers the extension of image fusion to video domain while preserving temporal consistency. Extensive experiments show state-of-the-art performance on IVIF and medical fusion tasks.
          </p>
        </div>
      </div>
    </div>

    <!-- Method -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <img src="./static/images/framework.png" alt="DAE-Fuse Architecture">
          <p>
            <b>Two-phase framework:</b> (1) Adversarial Feature Extraction Phase with Transformer-CNN parallel encoders. (2) Attention-Guided Cross-Modality Fusion Phase leveraging cross-attention and adversarial learning.
          </p>
        </div>
      </div>
    </div>

    <!-- Results -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>
        <div class="content">
          <h3 class="title is-4">Qualitative Comparison</h3>
          <img src="./static/images/result_comparison.png" alt="Qualitative Results">
          <p>
            DAE-Fuse preserves fine details (e.g., roof texture) and avoids modality bias compared to GAN/AE baselines.
          </p>

          <h3 class="title is-4">Quantitative Comparison</h3>
          <table class="table is-bordered">
            <thead><tr><th>Method</th><th>EN↑</th><th>SD↑</th><th>VIF↑</th></tr></thead>
            <tbody>
              <tr><td>DIDFuse</td><td>6.97</td><td>45.12</td><td>0.60</td></tr>
              <tr><td>Ours</td><td class="has-text-weight-bold">7.17</td><td class="has-text-weight-bold">46.63</td><td class="has-text-weight-bold">0.79</td></tr>
            </tbody>
          </table>
        </div>
      </div>
    </div>

    <!-- BibTeX -->
    <div class="columns is-centered">
      <div class="column is-full-width content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@article{guo2023dae-fuse,
  title={DAE-Fuse: An Adaptive Discriminative Autoencoder for Multi-Modality Image Fusion},
  author={Guo, Yuchen and Xu, Ruoxiang and Li, Rongcheng and Su, Weifeng},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023}
}</code></pre>
      </div>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>This website is licensed under <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>.</p>
    </div>
  </div>
</footer>

</body>
</html>
